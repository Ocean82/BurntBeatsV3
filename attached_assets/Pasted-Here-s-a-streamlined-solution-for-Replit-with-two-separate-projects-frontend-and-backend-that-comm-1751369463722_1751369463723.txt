Here's a streamlined solution for Replit with two separate projects (frontend and backend) that communicate via HTTP requests, without Docker:

Backend Repl (FastAPI + RVC/Bark)
Create a new Python Repl

File structure:

:

text

fastapi>=0.95.2
uvicorn>=0.22.0
python-multipart>=0.0.6
numpy>=1.24.3
soundfile>=0.12.1
(simplified for Replit):
python

from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import os
import uuid
from pathlib import Path
import numpy as np
import soundfile as sf
from fastapi.staticfiles import StaticFiles

app = FastAPI()

# Allow CORS for Replit frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# Mock voice engine (replace with actual RVC/Bark implementation)
class VoiceEngine:
    def create_voice_embedding(self, audio_path: str, voice_id: str) -> str:
        os.makedirs("embeddings", exist_ok=True)
        embedding_path = f"embeddings/{voice_id}.npy"
        np.save(embedding_path, np.random.rand(256))  # Mock embedding
        return embedding_path
    
    def synthesize(self, text: str, voice_id: str = None) -> str:
        os.makedirs("outputs", exist_ok=True)
        output_path = f"outputs/{uuid.uuid4()}.wav"
        # Generate silent audio as mock (replace with real synthesis)
        sf.write(output_path, np.zeros(16000), 16000)
        return output_path

engine = VoiceEngine()

@app.post("/register-voice")
async def register_voice(file: UploadFile = File(...)):
    try:
        voice_id = str(uuid.uuid4())
        os.makedirs("voices", exist_ok=True)
        file_path = f"voices/{voice_id}.wav"
        
        with open(file_path, "wb") as buffer:
            buffer.write(await file.read())
        
        embedding_path = engine.create_voice_embedding(file_path, voice_id)
        return {"voice_id": voice_id, "embedding_path": embedding_path}
    
    except Exception as e:
        raise HTTPException(500, str(e))

@app.post("/synthesize")
async def synthesize(text: str, voice_id: str = None):
    try:
        output_path = engine.synthesize(text, voice_id)
        return {"audio_url": f"/outputs/{Path(output_path).name}"}
    except Exception as e:
        raise HTTPException(500, str(e))

# Serve static files (audio outputs)
app.mount("/outputs", StaticFiles(directory="outputs"), name="outputs")

# For Replit deployment
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
Frontend Repl (React)
Create a new Node.js Repl

File structure:

 (simplified for Replit):

jsx

import React, { useState, useRef } from 'react';
import AudioPlayer from './components/AudioPlayer';

export default function App() {
  const [file, setFile] = useState(null);
  const [text, setText] = useState('');
  const [voiceId, setVoiceId] = useState('');
  const [audioUrl, setAudioUrl] = useState('');
  const [isProcessing, setIsProcessing] = useState(false);
  
  // Replace with your backend Repl URL
  const BACKEND_URL = "https://your-backend-username.backend-repl-name.repl.co";

  const handleUpload = async () => {
    if (!file) return;
    
    setIsProcessing(true);
    const formData = new FormData();
    formData.append('file', file);
    
    try {
      const response = await fetch(`${BACKEND_URL}/register-voice`, {
        method: 'POST',
        body: formData
      });
      const data = await response.json();
      setVoiceId(data.voice_id);
    } catch (error) {
      console.error("Upload failed:", error);
    } finally {
      setIsProcessing(false);
    }
  };

  const handleSynthesize = async () => {
    if (!text) return;
    
    setIsProcessing(true);
    try {
      const response = await fetch(`${BACKEND_URL}/synthesize?text=${encodeURIComponent(text)}&voice_id=${voiceId}`);
      const data = await response.json();
      setAudioUrl(`${BACKEND_URL}${data.audio_url}`);
    } catch (error) {
      console.error("Synthesis failed:", error);
    } finally {
      setIsProcessing(false);
    }
  };

  return (
    <div style={{ maxWidth: '800px', margin: '0 auto', padding: '20px' }}>
      <h1>Voice Cloning App</h1>
      
      <div style={{ marginBottom: '20px' }}>
        <h2>1. Upload Voice Sample</h2>
        <input 
          type="file" 
          accept="audio/*" 
          onChange={(e) => setFile(e.target.files[0])} 
        />
        <button 
          onClick={handleUpload}
          disabled={isProcessing || !file}
        >
          {isProcessing ? 'Uploading...' : 'Upload Voice'}
        </button>
      </div>
      
      <div style={{ marginBottom: '20px' }}>
        <h2>2. Enter Text</h2>
        <textarea
          value={text}
          onChange={(e) => setText(e.target.value)}
          placeholder="Type what you want the voice to say..."
          style={{ width: '100%', minHeight: '100px' }}
        />
      </div>
      
      <div style={{ marginBottom: '20px' }}>
        <button 
          onClick={handleSynthesize}
          disabled={isProcessing || !text}
        >
          {isProcessing ? 'Synthesizing...' : 'Generate Voice'}
        </button>
      </div>
      
      {audioUrl && (
        <div>
          <h2>Result:</h2>
          <AudioPlayer src={audioUrl} />
        </div>
      )}
    </div>
  );
}
:
jsx

import React from 'react';

export default function AudioPlayer({ src }) {
  return (
    <audio controls style={{ width: '100%' }}>
      <source src={src} type="audio/wav" />
      Your browser does not support the audio element.
    </audio>
  );
}
Connecting Both Repls
Backend Setup:

Run your backend Repl
Note the URL (looks like )
Frontend Setup:

Replace in the frontend code with your actual backend URL
Run the frontend Repl
Testing:

Upload a voice sample (WAV file works best)
Enter some text
Click "Generate Voice"
You should hear the output (mock audio until you implement RVC/Bark)
Adding Real RVC/Bark
To actually implement RVC or Bark:

For RVC:

Add and to
Clone the RVC repository into your Repl
Replace the mock synthesis with actual RVC inference
For Bark:

Add and to
Import and use Bark from HuggingFace
Remember Replit has limited resources, so you may need to:

Use smaller models
Add loading screens
Implement progress bars for longer operations
Add error handling for when operations time out
This setup gives you a complete pipeline without Docker that works within Replit's constraints.